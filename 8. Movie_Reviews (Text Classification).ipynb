{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Reviews\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "For this case-study, we are utilizing a data-set of about 2000 movie reviews. These reviews are full length reviews that have been classified as being both positive and negative.\n",
    "\n",
    "A sample review has been included below\n",
    "\n",
    "> how do films like mouse hunt get into theatres ? \n",
    "isn't there a law or something ? \n",
    "\n",
    ">this diabolical load of claptrap from steven speilberg's dreamworks studio is hollywood family fare at its deadly worst . \n",
    "mouse hunt takes the bare threads of a plot and tries to prop it up with overacting and flat-out stupid slapstick that makes comedies like jingle all the way look decent by comparison . \n",
    "writer adam rifkin and director gore verbinski are the names chiefly responsible for this swill . \n",
    "the plot , for what its worth , concerns two brothers ( nathan lane and an appalling lee evens ) who inherit a poorly run string factory and a seemingly worthless house from their eccentric father . \n",
    "deciding to check out the long-abandoned house , they soon learn that it's worth a fortune and set about selling it in auction to the highest bidder . \n",
    "but battling them at every turn is a very smart mouse , happy with his run-down little abode and wanting it to stay that way . \n",
    "the story alternates between unfunny scenes of the brothers bickering over what to do with their inheritance and endless action sequences as the two take on their increasingly determined furry foe . \n",
    "whatever promise the film starts with soon deteriorates into boring dialogue , terrible overacting , and increasingly uninspired slapstick that becomes all sound and fury , signifying nothing . \n",
    "the script becomes so unspeakably bad that the best line poor lee evens can utter after another run in with the rodent is : \" i hate that mouse \" . \n",
    "oh cringe ! \n",
    "\n",
    ">this is home alone all over again , and ten times worse . \n",
    "one touching scene early on is worth mentioning . \n",
    "we follow the mouse through a maze of walls and pipes until he arrives at his makeshift abode somewhere in a wall . \n",
    "he jumps into a tiny bed , pulls up a makeshift sheet and snuggles up to sleep , seemingly happy and just wanting to be left alone . \n",
    "it's a magical little moment in an otherwise soulless film . \n",
    "a message to speilberg : if you want dreamworks to be associated with some kind of artistic credibility , then either give all concerned in mouse hunt a swift kick up the arse or hire yourself some decent writers and directors . \n",
    "\n",
    ">this kind of rubbish will just not do at all . \n",
    "\n",
    "\n",
    "### Goal\n",
    "\n",
    "To classify the reviews as being positive or negative based on the text content of the reviews. \n",
    "\n",
    "\n",
    "### Result Summary\n",
    "The best model is able to attain an accuracy of 85% on the test data-set\n",
    "\n",
    "### Table of Contents\n",
    "1. Getting and Setting-up the data\n",
    "2. Data Exploration and Preperation \n",
    "3. Vectorizing the Data and Training Models\n",
    "4. Making the Best Model Better\n",
    "5. Prediction on New Data\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Getting and Setting-up Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Housekeeping\n",
    "\n",
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"Moview_Reviews\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "\n",
    "#create the reqired folders if they don't already exist\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "# A simple function that helps save images\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Housekeeping, Part 2\n",
    "\n",
    "# to make the plots larger in size\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 16,10\n",
    "\n",
    "\n",
    "# A set of libraries pertaining to forecasting methods\n",
    "\n",
    "# from statsmodels.tsa.arima_model import ARMA, ARIMA, ARMAResults, ARIMAResults\n",
    "# from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "# from statsmodels.tsa.stattools import adfuller\n",
    "# from pmdarima import auto_arima\n",
    "# from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "# from statsmodels.graphics.tsaplots import month_plot, quarter_plot\n",
    "# from statsmodels.tsa.statespace.tools import diff\n",
    "# from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "# from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "# from pmdarima import auto_arima\n",
    "# from statsmodels.tsa.filters.hp_filter import hpfilter\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the data\n",
    "\n",
    "df = pd.read_csv('/Users/ramavishwanathan/Desktop/Rama Files/purse/ml_all/NLP_Notes/TextFiles/moviereviews.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having a quick look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>how do films like mouse hunt get into theatres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>some talented actresses are blessed with a dem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>this has been an extraordinary year for austra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>according to hollywood movies made in last few...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>my first press screening of 1998 and already i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                             review\n",
       "0   neg  how do films like mouse hunt get into theatres...\n",
       "1   neg  some talented actresses are blessed with a dem...\n",
       "2   pos  this has been an extraordinary year for austra...\n",
       "3   pos  according to hollywood movies made in last few...\n",
       "4   neg  my first press screening of 1998 and already i..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 2 columns):\n",
      "label     2000 non-null object\n",
      "review    1965 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 31.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upon first viewing of this movie , the phrases \" been there \" and \" done that \" come quickly to mind . \r\n",
      "spy hard manages to steal almost every joke from the zucker brothers films , the most popular of which are airplane and the naked gun series . \r\n",
      "stealing stuff can be profitable in this industry , but only when you steal the right stuff . \r\n",
      "what little plot there is involves dick steele , aka . \r\n",
      "agent wd-40 ( leslie nielsen ) trying to save the world from an almost deranged madman played by andy griffith . \r\n",
      "along the way to it goal ( goal ? ) , the film manages to spoof mainly the james bond type films , but also manages to hit on films such as home alone and sister act . \r\n",
      "the trick about spoofing is that you have to actually be funny , or at the least , satirical . \r\n",
      "spy hard achieves neither , as it borrows all of the wrong elements from the superior zucker brothers films . \r\n",
      "the \" dick , the world is in danger . \r\n",
      "what is it ? \r\n",
      "well , it's a big roundish ball floating in space around the sun . . \r\n",
      " ( i'm paraphrasing ) \" type of exchange is used at least four times in the opening ten minutes of the film , each time getting progressively less funny . \r\n",
      "what they should have stolen were the background sight gags which were so effective in the zucker brother's films while writing their own dialogue . \r\n",
      "director rick friedberg focuses more on the mug shots of his actors ( especially nielsen , who can do this quite well ) than on the delivery and context of their lines , much of the time cutting the punchline short . \r\n",
      "the whole film seems to be in a race with itself to be over , as is evident in the final sequence , where there is no comedic denouement after the climax . \r\n",
      "as was usual in the zucker brothers films and in spy hard , the end credits tend to replace this by being out of context . \r\n",
      "one of the more amusing was , \" captain of the enterprise . . . . . . james \r\n",
      "t . kirk \" . \r\n",
      "overall , i thought this was a very weak effort . \r\n",
      "while all of the right films to spoof were chosen , they used none of the right spoofing methods . \r\n",
      "next time they should \" spy \" a little bit harder . \r\n",
      " * * * * = excellent . \r\n",
      "one of a kind . \r\n",
      "must see . \r\n",
      " * * * = entertaining . \r\n",
      "worth the price of admission . \r\n",
      " * * = fair . \r\n",
      "nothing much special . \r\n",
      " * = what were they thinking ? ? \r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# looking at the review column\n",
    "print(df['review'][10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## 2. Data Exploration and Preperation\n",
    "\n",
    "In this section, we will explore the data and importantly, prepare the analytical data-set.\n",
    "\n",
    "The sub-goals include:\n",
    "1. Identifying and Treating the data for missing values\n",
    "2. Dividing the Data into Training and Test Sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label      0\n",
       "review    35\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for missing values\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are **35 missing records (NAs)** for the review field. These **missing records will be dropped**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label     0\n",
       "review    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-checking for missing values\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to find any of the reviews are blank (Empty Strings). These **empty strings do not show as NAs and have to be detected separately**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 blanks:  [57, 71, 147, 151, 283, 307, 313, 323, 343, 351, 427, 501, 633, 675, 815, 851, 977, 1079, 1299, 1455, 1493, 1525, 1531, 1763, 1851, 1905, 1993]\n"
     ]
    }
   ],
   "source": [
    "# check and remove empty strings (same as missing values)\n",
    "# Author: Jose Portila, PIERIAN DATA\n",
    "\n",
    "blanks = []  # start with an empty list\n",
    "\n",
    "for i,lb,rv in df.itertuples():  # iterate over the DataFrame\n",
    "    if type(rv)==str:            # avoid NaN values\n",
    "        if rv.isspace():         # test 'review' for whitespace\n",
    "            blanks.append(i)     # add matching index numbers to the list\n",
    "        \n",
    "print(len(blanks), 'blanks: ', blanks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are **27 blank reviews** and these too have to be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(blanks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having a quick look at the counts of positive and negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    969\n",
       "pos    969\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a **fairly even split between positive and negative reviews**\n",
    "\n",
    "Now, the next step is to divide the data into **training and testing sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing the data into training and test sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['review']\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Vectorizing the Data and Training Models\n",
    "\n",
    "\n",
    "### Vectorizing Data\n",
    "\n",
    "The purpose of Vectorizing the data is to create a matrix of the comprehensive set of words which are found across all the reviews. *sparse* matrix is called **Document Term Matrix (DTM)**\n",
    "\n",
    "The **Document Term Matrix (DTM)** will be populated with **term frequency-inverse document frequency (TF-IDF)** for *each* word.\n",
    "\n",
    "An **(TF-IDF) factor** diminishes the weight of the terms that occur very frequently and increases the weight of the terms that occor rarely. This ensures that common words such as the articles, names of movie stars etc aren't overly influencial in the model.\n",
    "\n",
    "### Linear SVM Model\n",
    "\n",
    "Linear SVM is known to work well with text classification, so will be trying that out upfront.\n",
    "\n",
    "\n",
    "### Pipeline\n",
    "\n",
    "We'll use a pipeline to integrate the Vectorization and the model building steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "text_clf_lsvm = Pipeline([\n",
    "    ('tfidf',TfidfVectorizer()),\n",
    "    ('clf',LinearSVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implmenting Linear SVM\n",
    "text_clf_lsvm.fit(X_train, y_train)\n",
    "\n",
    "# Form a prediction set\n",
    "Y_test = text_clf_lsvm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[197  36]\n",
      " [ 37 215]]\n",
      "\n",
      "\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.84      0.85      0.84       233\n",
      "         pos       0.86      0.85      0.85       252\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       485\n",
      "   macro avg       0.85      0.85      0.85       485\n",
      "weighted avg       0.85      0.85      0.85       485\n",
      "\n",
      "\n",
      "\n",
      "Accuracy Score: \n",
      "0.8494845360824742\n"
     ]
    }
   ],
   "source": [
    "# A Great Utility, to quickly calculate classification metrics \n",
    "# MULTI CLASS SCENARIO\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test,Y_test))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test,Y_test))\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy Score: \")\n",
    "print(accuracy_score(y_test,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are getting an **accuracy of 85% which is very good.** \n",
    "\n",
    "The other great thig is that there is a great consistency in the precision and recall values which indicates that the model is well balanced.\n",
    "\n",
    "A quick Recap of Precision and Recall Concepts \n",
    "* Precision: Proportion of True Positive among all the Positive cases identified\n",
    "* Recall: Propotion of True Positive among the set of Positive cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## 4. Making the Model Better - Adding StopWords\n",
    "\n",
    "We are looking at a short-list of about 60 stop words\n",
    "\n",
    "More details:\n",
    "By default, **CountVectorizer** and **TfidfVectorizer** do not filter stopwords. However, they **offer some optional settings, including passing in your own stopword list**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['a', 'about', 'an', 'and', 'are', 'as', 'at', 'be', 'been', 'but', 'by', 'can', \\\n",
    "             'even', 'ever', 'for', 'from', 'get', 'had', 'has', 'have', 'he', 'her', 'hers', 'his', \\\n",
    "             'how', 'i', 'if', 'in', 'into', 'is', 'it', 'its', 'just', 'me', 'my', 'of', 'on', 'or', \\\n",
    "             'see', 'seen', 'she', 'so', 'than', 'that', 'the', 'their', 'there', 'they', 'this', \\\n",
    "             'to', 'was', 'we', 'were', 'what', 'when', 'which', 'who', 'will', 'with', 'you']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN THIS CELL TO ADD STOPWORDS TO THE LINEAR SVC PIPELINE:\n",
    "# ADD A STOPWORDS HYPERPARAMETER to the TfidVectorizer\n",
    "\n",
    "# Executing Pipeline\n",
    "text_clf_lsvc2 = Pipeline([('tfidf', TfidfVectorizer(stop_words=stopwords)),\n",
    "                     ('clf', LinearSVC()),\n",
    "])\n",
    "\n",
    "# Fitting Model\n",
    "text_clf_lsvc2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form a prediction set\n",
    "Y_test = text_clf_lsvc2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[195  38]\n",
      " [ 38 214]]\n",
      "\n",
      "\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.84      0.84      0.84       233\n",
      "         pos       0.85      0.85      0.85       252\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       485\n",
      "   macro avg       0.84      0.84      0.84       485\n",
      "weighted avg       0.84      0.84      0.84       485\n",
      "\n",
      "\n",
      "\n",
      "Accuracy Score: \n",
      "0.843298969072165\n"
     ]
    }
   ],
   "source": [
    "# A Great Utility, to quickly calculate classification metrics \n",
    "# MULTI CLASS SCENARIO\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test,Y_test))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test,Y_test))\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy Score: \")\n",
    "print(accuracy_score(y_test,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite adding StopWords, the best model is still is the initial version of the SVM model.\n",
    "\n",
    "***\n",
    "\n",
    "## 5. Prediction on New Data\n",
    "\n",
    "The following is ow the model can be imnplemented on new data (reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "myreview = \"A movie I really wanted to love was terrible. \\\n",
    "I'm sure the producers had the best intentions, but the execution was lacking.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neg']\n"
     ]
    }
   ],
   "source": [
    "print(text_clf_lsvc2.predict([myreview]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
